{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMElNz7KlEhNBbOoAK//AtZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hd77alu/ml-formative3/blob/main/ml_formative3_g6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Formative 3 - Probability Distributions, Bayesian Probability, and Gradient Descent Implementation"
      ],
      "metadata": {
        "id": "W0vhzffP05AT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Probability Distributions"
      ],
      "metadata": {
        "id": "FqTu_QIu4vNc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. Using a relevant dataset sourced online, you will compute the probability density values for each data point using the bivariate normal distribution formula. Implement this from scratch without using any statistical libraries in Python.\n",
        "\n",
        "2. Visualize the PDF with Matplotlib using a contour plot and a 3D plot.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_DKu5OaI5wGj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fuQJhihb6EnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Bayesian Probability"
      ],
      "metadata": {
        "id": "Oo5Q2xyz46EU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will use [IMDb Movie Reviews](https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews) DatasetLinks to an external site. for this part of the assignment. Load the dataset using pandas\n",
        "\n",
        "1. Keyword Selection\n",
        "\n",
        "- As a group, choose 2–4 keywords that you believe indicate positive sentiment and 2–4 keywords that indicate negative sentiment.\n",
        "\n",
        "2. Choice of Conditional Probability\n",
        "\n",
        "- Decide whether your group will calculate P(Positive | keyword) or P(Negative | keyword) —\n",
        "do not compute both.\n",
        "\n",
        "3. Computation and Presentation\n",
        "\n",
        "- For each chosen keyword, create a small table or markdown block showing the following probabilities:\n",
        "\n",
        "- Prior: P(Positive)\n",
        "\n",
        "- Likelihood: P(keyword|Positive)\n",
        "\n",
        "- Marginal:  P(keyword)\n",
        "\n",
        "- Posterior:  P(Positive|keyword)\n",
        "\n",
        "4. Implementation\n",
        "\n",
        "- Implement Bayes’ Theorem in Python to compute the posterior probability for each keyword based on your selected dataset.\n",
        "\n",
        "- You may use basic Python operations only (no external machine learning libraries)."
      ],
      "metadata": {
        "id": "WKUnubjW6QJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mdiNS3AW9gg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Gradient Descent Manual Calculation"
      ],
      "metadata": {
        "id": "-1AA6NAL4--2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Objective:\n",
        "You will manually compute three updates of the gradient descent algorithm for the parameters and in a simple linear regression model.\n",
        "\n",
        "- Instructions:\n",
        "\n",
        "1. Given the linear equation where: y = mx + b\n",
        "\n",
        "- Initial m = -1\n",
        "- Initial b = 1\n",
        "- Learning rate = 0.1\n",
        "- Given points: (1,3) and (3,6)\n",
        "\n",
        "2. Compute the predicted values (y) for each data point using the current values of (m) and (b)\n",
        "\n",
        "3. Derive the gradient of the cost function J(m,b), using Mean Squared Error (MSE). In Essence, show the calculation steps to arrive at the derivative of the cost function\n",
        "\n",
        "4. Iteratively Update (m) and (b) using gradient descent\n",
        "\n",
        "- The number of times you will update m and b is equal to the number of members that are in each respective group\n",
        "- Show all calculations clearly and include intermediate results after each step.\n",
        "- Each member must do at least 1 iteration Describe the trend you observe in the values of and. Are they moving towards reducing the error?\n",
        "\n",
        "5. Submission:\n",
        "Submit a neatly written  document with all calculations."
      ],
      "metadata": {
        "id": "pN9a4ljJ7KF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Gradient Descent in Code"
      ],
      "metadata": {
        "id": "Ud5qSXpp5bOI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Convert the manual calculations into Python code using SciPy.\n",
        "2. Write code to :\n",
        "- Update the values of m and b\n",
        "- Compute predictions (the value of Y) using the final values of\n",
        " m and b.\n",
        "3. Ensure the code does not abstract the update process excessively, meaning each step should be clearly visible.\n",
        "4. Visualize how m, b, and the Error change over iterations using Matplotlib in two separate plots."
      ],
      "metadata": {
        "id": "JONUbyCt9o8t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3rHCrSm-7Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Things to Note"
      ],
      "metadata": {
        "id": "bt87Vmlt5iGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any Generic responses will result in a heavy penalty."
      ],
      "metadata": {
        "id": "5PBFwHX0-TpP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission"
      ],
      "metadata": {
        "id": "nMIfEZm95o6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- A GitHub Repository\n",
        "- Jupyter Notebook with all implementations. Insert relevant images in the notebook to make an enticing presentation.\n",
        "- A NEAT PDF showing handwritten Manual Calculations of Part 3\n",
        "- A PDF file Showing Contributions\n",
        "\n",
        "(Any code presented must be modular and follow the DRY principle)"
      ],
      "metadata": {
        "id": "DTkaO7dx-dWo"
      }
    }
  ]
}